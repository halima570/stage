{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e52a9efe-4255-4b3f-9e7c-6d8b54e5e7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Inputs shape: (None, 3136, 1)\n",
      "Weights shape: (2, 3136, 16, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"capsule_layer_19\" (type CapsuleLayer).\n\nin user code:\n\n    File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_1516\\3551267341.py\", line 77, in call  *\n        inputs = K.dot(inputs, self.W)  # Shape: (batch_size, num_capsules, num_capsules, dim_capsule)\n    File \"C:\\Users\\LENOVO\\anaconda3\\envs\\CI\\lib\\site-packages\\keras\\backend.py\", line 2450, in dot\n        tf.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:]\n\n    ValueError: Dimensions must be equal, but are 1 and 16 for '{{node capsule_layer_19/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](capsule_layer_19/Reshape_1, capsule_layer_19/Reshape_2)' with input shapes: [?,1], [16,6272].\n\n\nCall arguments received by layer \"capsule_layer_19\" (type CapsuleLayer):\n  • inputs=tf.Tensor(shape=(None, 3136, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 97\u001b[0m\n\u001b[0;32m     94\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     95\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 97\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCapsNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     99\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m    100\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    101\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mPrecision()]\n\u001b[0;32m    102\u001b[0m )\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[46], line 89\u001b[0m, in \u001b[0;36mCapsNet\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m     87\u001b[0m primarycaps \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mReshape(target_shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m])(primarycaps)\n\u001b[0;32m     88\u001b[0m primarycaps \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: K\u001b[38;5;241m.\u001b[39msqrt(K\u001b[38;5;241m.\u001b[39msum(K\u001b[38;5;241m.\u001b[39msquare(x), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)))(primarycaps)\n\u001b[1;32m---> 89\u001b[0m digitcaps \u001b[38;5;241m=\u001b[39m \u001b[43mCapsuleLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_capsules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_capsule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroutings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimarycaps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m out_caps \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: K\u001b[38;5;241m.\u001b[39msqrt(K\u001b[38;5;241m.\u001b[39msum(K\u001b[38;5;241m.\u001b[39msquare(x), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))(digitcaps)\n\u001b[0;32m     91\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mx, outputs\u001b[38;5;241m=\u001b[39mout_caps)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CI\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filelzj3rb5u.py:17\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     15\u001b[0m inputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39mtile, (ag__\u001b[38;5;241m.\u001b[39mld(inputs), [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mnum_capsules, \u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39mint_shape, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39mint_shape, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mW,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDimension mismatch for dot product.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 17\u001b[0m inputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39mdot, (ag__\u001b[38;5;241m.\u001b[39mld(inputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mW), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39msum, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), fscope)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"capsule_layer_19\" (type CapsuleLayer).\n\nin user code:\n\n    File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_1516\\3551267341.py\", line 77, in call  *\n        inputs = K.dot(inputs, self.W)  # Shape: (batch_size, num_capsules, num_capsules, dim_capsule)\n    File \"C:\\Users\\LENOVO\\anaconda3\\envs\\CI\\lib\\site-packages\\keras\\backend.py\", line 2450, in dot\n        tf.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:]\n\n    ValueError: Dimensions must be equal, but are 1 and 16 for '{{node capsule_layer_19/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](capsule_layer_19/Reshape_1, capsule_layer_19/Reshape_2)' with input shapes: [?,1], [16,6272].\n\n\nCall arguments received by layer \"capsule_layer_19\" (type CapsuleLayer):\n  • inputs=tf.Tensor(shape=(None, 3136, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from PIL import Image\n",
    "\n",
    "# Définir les chemins des données\n",
    "train_dir =r'C:\\Users\\LENOVO\\Downloads\\archive\\chest_xray\\train' \n",
    "val_dir = r'C:\\Users\\LENOVO\\Downloads\\archive\\chest_xray\\val' \n",
    "test_dir = r'C:\\Users\\LENOVO\\Downloads\\archive\\chest_xray\\test'\n",
    "# Création des générateurs d'images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255) \n",
    "val_datagen = ImageDataGenerator(rescale=1./255) \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir,\n",
    "target_size=(128, 128),\n",
    "batch_size=32,\n",
    "class_mode='binary')\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "test_dir,\n",
    "target_size=(128, 128),\n",
    "batch_size=32,\n",
    "class_mode='binary')\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "val_dir,\n",
    "target_size=(128, 128),\n",
    "batch_size=32,\n",
    "class_mode='binary')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class CapsuleLayer(Layer):\n",
    "    def __init__(self, num_capsules, dim_capsule, routings, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = tuple(input_shape)\n",
    "\n",
    "        assert len(input_shape) == 3\n",
    "        self.input_num_capsules = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Initialisation des poids pour le routage des capsules\n",
    "        self.W = self.add_weight(\n",
    "            shape=[self.num_capsules, self.input_num_capsules, self.dim_capsule, self.input_dim_capsule],\n",
    "            initializer='glorot_uniform',\n",
    "            name='W'\n",
    "        )\n",
    "        super(CapsuleLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs_shape = K.int_shape(inputs)\n",
    "        print(\"Inputs shape:\", inputs_shape)\n",
    "        print(\"Weights shape:\", K.int_shape(self.W))\n",
    "\n",
    "        # Ajustement de la forme de self.W si nécessaire\n",
    "        self.W = K.reshape(self.W, (self.num_capsules, self.input_num_capsules, self.dim_capsule, self.input_dim_capsule))\n",
    "\n",
    "        # Expansion des dimensions et répétition\n",
    "        inputs = K.expand_dims(inputs, 2)  # Shape: (batch_size, num_capsules, 1, input_dim_capsule)\n",
    "        inputs = K.tile(inputs, [1, 1, self.num_capsules, 1])  # Répéter pour le routage\n",
    "\n",
    "        # Assurez-vous que les dimensions correspondent avant la multiplication matricielle\n",
    "        assert K.int_shape(inputs)[-1] == K.int_shape(self.W)[-1], \"Dimension mismatch for dot product.\"\n",
    "\n",
    "        inputs = K.dot(inputs, self.W)  # Shape: (batch_size, num_capsules, num_capsules, dim_capsule)\n",
    "\n",
    "        # Implémentation simplifiée de l'algorithme de routage\n",
    "        inputs = K.sum(inputs, axis=2)\n",
    "        return inputs\n",
    "\n",
    "def CapsNet(input_shape, num_classes):\n",
    "    x = layers.Input(shape=input_shape)\n",
    "    conv1 = layers.Conv2D(256, (9, 9), strides=1, padding='valid', activation='relu')(x)\n",
    "    primarycaps = layers.Conv2D(8, (9, 9), strides=2, padding='valid', activation='relu')(conv1)\n",
    "    primarycaps = layers.Reshape(target_shape=[-1, 8])(primarycaps)\n",
    "    primarycaps = layers.Lambda(lambda x: K.sqrt(K.sum(K.square(x), axis=-1, keepdims=True)))(primarycaps)\n",
    "    digitcaps = CapsuleLayer(num_capsules=num_classes, dim_capsule=16, routings=3)(primarycaps)\n",
    "    out_caps = layers.Lambda(lambda x: K.sqrt(K.sum(K.square(x), axis=-1)))(digitcaps)\n",
    "    model = models.Model(inputs=x, outputs=out_caps)\n",
    "    return model\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 2\n",
    "\n",
    "model = CapsNet(input_shape=input_shape, num_classes=num_classes)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.Precision()]\n",
    ")\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    epochs=50\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
